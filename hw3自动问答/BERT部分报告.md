### BERT预训练模型

##### 数据预处理：

本次作业中，数据集的格式为：问题 + 句子 + 0/1标签，一个问题对应一篇文章，而这篇文章被拆分为许多分句，句子中是否含有答案用01标签标注。尽管是问答问题，但数据集的形式具有分类任务的形式。经过考虑，我们优先考虑用基于问答的方式来处理数据，也就是在用于SQuAD的BERT上fine-tune模型。原因如下：

1. 作业数据集是将同一篇文章拆分成许多句子，这些句子之间的顺序可能会给答案作出贡献；

2. 问题文本提供了对答案范围的限制，如人名、地名、时间这些答案类型；但在缺乏全文信息的情况下，可能有“张冠李戴”的情况，选出并不符合问题信息的同类答案。

而基于问答处理的处理方法也有一些缺陷：在数据集中，我们发现一些问题的答案在文章中出现多次。SQuAD模型原本从文章中输出一段的输出方式不适合答案多次出现的情况。因此，在预训练模型输出答案片段后，我们与所有句子进行比对，这样就能得到多个答案的情况。

为了对比考虑全文的预训练模型与拆分成单句的预训练模型效果，我们也用分类任务的BERT模型进行了fine-tuning。

##### 结果：

基于问答的BERT模型：

【图呢？】

基于分类的BERT模型：

【图呢？】

以上结果均在validation-set上得出。

##### 结果分析：

分类结果明显更好，和数据预处理时的猜测并不符合。可能有如下情况：

1. 问答模型输出的答案片段不够准确，出现答案片段跨两个句子，无法正确标注等情况。但在检查结果时发现，答案片段基本都刚好是一个分句，无跨句情况。猜测是模型学习到了答案由标点分割的特点。

2. 数据不够强。

   【找几个数据集截图，大意是一段文章中可能就出现一次时间一次地点一次人物，没啥干扰】

3. BERT分类就是强？？？









